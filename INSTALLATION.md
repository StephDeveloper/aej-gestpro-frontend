# üõ†Ô∏è Installation et ex√©cution du projet GestPro

## Pr√©requis

- Node.js v18+
- PHP 8.1+
- Composer
- PostgreSQL
- Angular CLI
- Laravel CLI
- Ollama install√© localement

---

## üì¶ Backend (Laravel)

Apr√®s avoir r√©cup√©r√© le projet Laravel aej-gestpro-backend rendez vous √† la racine du projet et installez les d√©pendances
```bash
cd backend
composer install
```

Ex√©cutez √©galement cette commande pour cr√©er le fichier d'environnement .env
```bash
cp .env.example .env
```
Configurez le fichier d'environnement comme suit :
### üìÑ Configuration `.env` (extrait)
```
DB_CONNECTION=pgsql
DB_HOST=127.0.0.1
DB_PORT=5432
DB_DATABASE=gestpro
DB_USERNAME=postgres
DB_PASSWORD=your_password

MAIL_MAILER=smtp
MAIL_HOST=localhost
MAIL_PORT=1025
MAIL_USERNAME=null
MAIL_PASSWORD=null
MAIL_ENCRYPTION=null
MAIL_FROM_ADDRESS="info@gestpro.ci"
MAIL_FROM_NAME="GestPro"

OLLAMA_API_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=llama3.2:latest
```

Ex√©cutez les commandes ci-dessous pour permettre la cr√©ation des tables dans la base de donn√©es PostgreSQL 
et pour d√©marrer le serveur local. Assurez vous d'avoir install√© PostgreSQL üòÇ
```bash
php artisan migrate
php artisan serve
```

### ‚úâÔ∏è D√©marrez le simulateur d'envoi et de r√©ception de mail `MailHog`
Pour utiliser le simulateur d'email suivez ces instructions : 
- Lancez le fichier ex√©cutable MailHog_windows_386.exe (se trouvant dans la racine du projet Laravel)
- Reduisez le terminal ouvert puis ouvrez votre navigateur et acc√©dez √† cette adresse http://localhost:8025
- Vous recevrez dans le menu Inbox les diff√©rents mails de soumission de projets des promoteur
---


## üåê Frontend (Angular)

Apr√®s avoir r√©cup√©r√© le projet Angular aej-gestpro-frontend rendez vous √† la racine du projet, 
installez les d√©pendances et d√©marrez le serveur qui s'ex√©cutera sur cette adresse http://localhost:4200
```bash
cd frontend
npm install
npm run start
```

---

## üß† Lancer le moteur IA (Ollama)

```bash
ollama run llama3.2:latest
```

Assurez-vous avant tout que vous avez install√© ollama sur votre machine. Si ce n'est pas encore le cas suivez ces instructions : 
- Rendez vous sur le site https://ollama.com
- Cliquez sur le menu Models en haut √† gauche
- Dans la barre de recherche tapez llama3.2 puis cliquez sur le r√©sultat de recherche llama3.2
- S√©lectionnez le nombre de param√®tres en fonction des performances de votre machine puis copiez la commande correspondante
- Ouvrez la commande cmd et copier coller puis lancer la commande. (Ex: ollama run llama3.2) dans mon cas.
- Attendez la fin de l'installation et profitez de l'IA en locale.
